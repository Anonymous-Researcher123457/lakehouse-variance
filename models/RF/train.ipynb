{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a814fcf-0d33-4c98-b572-71602209f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from Model.sql_encoder import TextSQLEncoder\n",
    "from Model.Dataloader import prepare_data_for_rf\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "def write_predictions_and_labels(y_test, predictions, filename=\"values.scv\"):\n",
    "    \"\"\"\n",
    "    Write prediction/label pairs to a CSV-like file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : array-like\n",
    "        True labels.\n",
    "    predictions : array-like\n",
    "        Predicted values (same length as y_test).\n",
    "    filename : str\n",
    "        Output file name (default: 'values.scv').\n",
    "    \"\"\"\n",
    "    if len(y_test) != len(predictions):\n",
    "        raise ValueError(\n",
    "            f\"Length mismatch: len(y_test)={len(y_test)} \"\n",
    "            f\"but len(predictions)={len(predictions)}\"\n",
    "        )\n",
    "\n",
    "    with open(filename, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"prediction\", \"label\"])\n",
    "        for pred, label in zip(predictions, y_test):\n",
    "            writer.writerow([float(pred), float(label)])\n",
    "\n",
    "\n",
    "\n",
    "def run_random_forrest_model(train_df, test_df, database, results_dir):\n",
    "    test_file_path = Path(f\"{results_dir}/results.txt\").resolve()\n",
    "    SEED = 0\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    # LABEL\n",
    "    runtime = \"Runtime (s)\"\n",
    "    runtime_log = \"Runtime_log\"\n",
    "    label = runtime\n",
    "    \n",
    "    sql_encoder = TextSQLEncoder()\n",
    "       \n",
    "    grid = {\n",
    "        \"n_estimators\": [200, 400, 800],\n",
    "        \"max_depth\": [None, 10, 20, 40],\n",
    "    \n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \n",
    "        \"min_samples_split\": [2, 5, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 20],\n",
    "    \n",
    "        \"max_leaf_nodes\": [None, 1000],  \n",
    "    \n",
    "        \"bootstrap\": [True],\n",
    "        \"random_state\": [SEED],\n",
    "    }\n",
    "  \n",
    "    trainer = EncoderTrainerRF(\n",
    "        train_df=train_df,\n",
    "        test_df=test_df,\n",
    "        hyper_param_grid=grid,\n",
    "        dataframe_label=label,\n",
    "        results_path=results_dir,\n",
    "        sql_encoder=sql_encoder,\n",
    "        schema_encoder=None,\n",
    "        task_type=\"Regression\",\n",
    "        seed=SEED\n",
    "    )\n",
    "    \n",
    "    best_params = trainer.optimize_model()\n",
    "    \n",
    "    return trainer.evaluate_model()\n",
    "    \n",
    "\n",
    "class EncoderTrainerRF:\n",
    "    \"\"\"\n",
    "    Trainer for the Random Forest model using the TriEncoder framework.\n",
    "    Supports hyperparameter tuning using Grid Search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_df,\n",
    "                 test_df,\n",
    "                 hyper_param_grid,\n",
    "                 dataframe_label,\n",
    "                 results_path,\n",
    "                 sql_encoder,\n",
    "                 schema_encoder=None,\n",
    "                 task_type=\"Regression\",\n",
    "                 seed=SEED):\n",
    "        \n",
    "        self.model = None\n",
    "        self.task_type = task_type\n",
    "        self.dataframe_label = dataframe_label\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.grid = hyper_param_grid\n",
    "\n",
    "        self.results_path = results_path\n",
    "\n",
    "        self.sql_encoder = sql_encoder\n",
    "        self.schema_encoder = schema_encoder\n",
    "\n",
    "        self.seed = seed\n",
    "            \n",
    "        self.model_cls = RandomForestRegressor\n",
    "        self.scoring_approach = \"neg_mean_absolute_error\"\n",
    "        self.train_df = self.create_labels_regression(self.train_df, self.dataframe_label)\n",
    "        self.test_df = self.create_labels_regression(self.test_df, self.dataframe_label)\n",
    "        self.grid_search_args = {\"estimator\":self.model_cls(),\"param_grid\":self.grid,\"cv\":5,\"n_jobs\":-1,\"verbose\":0, \"scoring\":self.scoring_approach}\n",
    "            \n",
    "        self.X_train, self.y_train, self.train_feature_names, pca_model, query_ids = prepare_data_for_rf(train_df, sql_encoder, schema_encoder)\n",
    "        self.X_test, self.y_test, self.test_feature_names, _, query_ids = prepare_data_for_rf(test_df, sql_encoder, schema_encoder, pca_model=pca_model)\n",
    "\n",
    "\n",
    "    def optimize_model(self, params=None):\n",
    "        \"\"\"\n",
    "        Uses GridSearchCV to find the best hyperparameters for the Random Forest model.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if params is None:\n",
    "            grid_search = GridSearchCV(**self.grid_search_args)\n",
    "            grid_search.fit(self.X_train, self.y_train)\n",
    "            self.model = grid_search.best_estimator_\n",
    "            params = grid_search.best_params_\n",
    "        else:\n",
    "            self.model = RandomForestRegressor(**params)\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        return params\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Trains the Random Forest model using the best hyperparameters found.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = self.model_cls()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the test set.\n",
    "        \"\"\"\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "\n",
    "        if self.dataframe_label == \"Runtime_log\":\n",
    "            predictions = np.exp(predictions)\n",
    "            self.y_test = np.exp(self.y_test)\n",
    "        \n",
    "        \n",
    "        mae = mean_absolute_error(self.y_test, predictions)\n",
    "\n",
    "        def percentile_qerror(y_true, y_pred, percentile, min_runtime=1e-3):\n",
    "            y_true = np.asarray(y_true, float)\n",
    "            y_pred = np.asarray(y_pred, float)\n",
    "        \n",
    "            mask = (y_true > 0) & (y_pred > 0)\n",
    "            y_true = y_true[mask]\n",
    "            y_pred = y_pred[mask]\n",
    "        \n",
    "            qerr = np.maximum(y_true, y_pred) / np.maximum(\n",
    "                np.minimum(y_true, y_pred),\n",
    "                min_runtime,   \n",
    "            )\n",
    "\n",
    "            return float(np.percentile(qerr, percentile))\n",
    "        med_qerr = percentile_qerror(self.y_test, predictions, 50)  \n",
    "        p99_qerr = percentile_qerror(self.y_test, predictions, 99)  \n",
    "\n",
    "        metrics = {f\"MAE\": mae, f\"P50 QError\": med_qerr, \"P99 QError\": p99_qerr}\n",
    "        \n",
    "        with open(Path(f\"{self.results_path}/results_{self.sql_encoder.type}.txt\").resolve(), \"w\") as f:\n",
    "            f.write(f\"MAE: {mae:.3f}\\n\")\n",
    "            f.write(f\"P50 QError: {med_qerr:.3f}\\n\")\n",
    "            f.write(f\"P99 QError: {p99_qerr:.3f}\\n\")\n",
    "\n",
    "\n",
    "        return metrics, self.y_test, predictions\n",
    "\n",
    "\n",
    "    def create_labels_regression(self, df, col_to_use):\n",
    "        df[\"label\"] = df[col_to_use]\n",
    "        return df\n",
    "\n",
    "def load_ndjson_to_dataframe(ndjson_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_json(ndjson_path, lines=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b48b56-457a-42b8-97cc-5c945523ea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Database tpcds ====================\n",
      "                   Type Baseline              \n",
      " mae: 27.743041607733502 p50: 3.727157953363196 p99: 283.716254014489\n",
      "                   Type Local              \n",
      " mae: 17.40306014869141 p50: 5.643215112190589 p99: 223.60647912807664\n",
      "================== Database imdb ====================\n",
      "                   Type Baseline              \n",
      " mae: 4.520892242283718 p50: 6.371713195264505 p99: 63.6982845186182\n",
      "                   Type Local              \n",
      " mae: 4.395383971975081 p50: 6.529344561966711 p99: 64.0482651674412\n",
      "================== Database ssb ====================\n",
      "                   Type Baseline              \n",
      " mae: 43.66075170029343 p50: 2.870081847780856 p99: 429.98917545401184\n",
      "                   Type Local              \n",
      " mae: 11.081604841681557 p50: 2.423744469087278 p99: 115.59088047639584\n"
     ]
    }
   ],
   "source": [
    "DATABASES = [\"tpcds\", \"imdb\", \"ssb\"]\n",
    "RAWFILES = [\"Baseline\", \"Local\"]\n",
    "\n",
    "for DATABASE in DATABASES:\n",
    "\n",
    "    print(f\"================== Database {DATABASE} ====================\")\n",
    "    for RAWFILE in RAWFILES:\n",
    "        print(f\"Type {RAWFILE}\")\n",
    "        experiment_name = f\"{RAWFILE}_{DATABASE}\"\n",
    "        experimemt_query_path=\"../Queries\"\n",
    "\n",
    "        query_path = Path(experimemt_query_path).resolve()\n",
    "        query_dir = query_path / experiment_name\n",
    "        query_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        rf_train_path = f\"{query_dir}/{DATABASE}_{RAWFILE}_train.ndjson\"\n",
    "        rf_test_path = f\"{query_dir}/{DATABASE}_{RAWFILE}_test.ndjson\"\n",
    "\n",
    "\n",
    "        train_df = load_ndjson_to_dataframe(rf_train_path)\n",
    "        test_df  = load_ndjson_to_dataframe(rf_test_path)\n",
    "\n",
    "        metrics, labels, preds = run_random_forrest_model(train_df, test_df, database=DATABASE, results_dir=f\"./Results/{experiment_name}\")\n",
    "\n",
    "        print(f\" mae: {metrics['MAE']} p50: {metrics['P50 QError']} p99: {metrics['P99 QError']}\")\n",
    "        write_predictions_and_labels(labels, preds, filename=f\"./Results/{experiment_name}/values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741fd844-a3e5-442e-b7eb-1c73b1b1f5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfcfe0b-5b8a-40ba-abdb-323f07ccf4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
